{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.4.0 (SDL 2.26.4, Python 3.10.2)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import utils as ut\n",
    "import RNN as rnn\n",
    "import loss_functions as lf\n",
    "import plot_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "# import pygame as pg\n",
    "from visualisers.pg_visualiser import py_visualiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "rng = np.random.default_rng(2048)\n",
    "n_epochs = 1000\n",
    "batch_size = None\n",
    "len_seq = 2\n",
    "spacial_dim = 3\n",
    "n_hidden = 32\n",
    "test_indx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "raw_data, inputs, targets = ut.prep_data('lorenz', len_seq)\n",
    "inputs[-1]\n",
    "\n",
    "train_test, sequenced_train_test = ut.train_test_split(\n",
    "    inputs, targets, train_size, len_seq, spacial_dim\n",
    ")\n",
    "\n",
    "train_inputs, test_inputs, train_targets, test_targets = train_test\n",
    "(\n",
    "    sequenced_train_inputs,\n",
    "    sequenced_test_inputs,\n",
    "    sequenced_train_targets,\n",
    "    sequenced_test_targets,\n",
    ") = sequenced_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Batch size is default to None\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 18:40:55.774435: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 1s 1ms/step - loss: 8.1485\n",
      "Epoch 2/1000\n",
      "200/200 [==============================] - 0s 702us/step - loss: 0.1526\n",
      "Epoch 3/1000\n",
      "200/200 [==============================] - 0s 632us/step - loss: 0.1091\n",
      "Epoch 4/1000\n",
      "200/200 [==============================] - 0s 634us/step - loss: 0.0822\n",
      "Epoch 5/1000\n",
      "200/200 [==============================] - 0s 642us/step - loss: 0.0587\n",
      "Epoch 6/1000\n",
      "200/200 [==============================] - 0s 627us/step - loss: 0.0440\n",
      "Epoch 7/1000\n",
      "200/200 [==============================] - 0s 585us/step - loss: 0.0340\n",
      "Epoch 8/1000\n",
      "200/200 [==============================] - 0s 605us/step - loss: 0.0295\n",
      "Epoch 9/1000\n",
      "200/200 [==============================] - 0s 614us/step - loss: 0.0250\n",
      "Epoch 10/1000\n",
      "200/200 [==============================] - 0s 593us/step - loss: 0.0225\n",
      "Epoch 11/1000\n",
      "200/200 [==============================] - 0s 592us/step - loss: 0.0208\n",
      "Epoch 12/1000\n",
      "200/200 [==============================] - 0s 602us/step - loss: 0.0215\n",
      "Epoch 13/1000\n",
      "200/200 [==============================] - 0s 611us/step - loss: 0.0184\n",
      "Epoch 14/1000\n",
      "200/200 [==============================] - 0s 608us/step - loss: 0.0169\n",
      "Epoch 15/1000\n",
      "200/200 [==============================] - 0s 601us/step - loss: 0.0161\n",
      "Epoch 16/1000\n",
      "200/200 [==============================] - 0s 623us/step - loss: 0.0154\n",
      "Epoch 17/1000\n",
      "200/200 [==============================] - 0s 586us/step - loss: 0.0152\n",
      "Epoch 18/1000\n",
      "200/200 [==============================] - 0s 640us/step - loss: 0.0146\n",
      "Epoch 19/1000\n",
      "200/200 [==============================] - 0s 645us/step - loss: 0.0144\n",
      "Epoch 20/1000\n",
      "200/200 [==============================] - 0s 615us/step - loss: 0.0144\n",
      "Epoch 21/1000\n",
      "200/200 [==============================] - 0s 610us/step - loss: 0.0146\n",
      "Epoch 22/1000\n",
      "200/200 [==============================] - 0s 629us/step - loss: 0.0125\n",
      "Epoch 23/1000\n",
      "200/200 [==============================] - 0s 605us/step - loss: 0.0120\n",
      "Epoch 24/1000\n",
      "200/200 [==============================] - 0s 596us/step - loss: 0.0143\n",
      "Epoch 25/1000\n",
      "200/200 [==============================] - 0s 583us/step - loss: 0.0114\n",
      "Epoch 26/1000\n",
      "200/200 [==============================] - 0s 633us/step - loss: 0.0111\n",
      "Epoch 27/1000\n",
      "200/200 [==============================] - 0s 615us/step - loss: 0.0113\n",
      "Epoch 28/1000\n",
      "200/200 [==============================] - 0s 883us/step - loss: 0.0101\n",
      "Epoch 29/1000\n",
      "200/200 [==============================] - 0s 583us/step - loss: 0.0106\n",
      "Epoch 30/1000\n",
      "200/200 [==============================] - 0s 578us/step - loss: 0.0096\n",
      "Epoch 31/1000\n",
      "200/200 [==============================] - 0s 581us/step - loss: 0.0086\n",
      "Epoch 32/1000\n",
      "200/200 [==============================] - 0s 813us/step - loss: 0.0088\n",
      "Epoch 33/1000\n",
      "200/200 [==============================] - 0s 606us/step - loss: 0.0092\n",
      "Epoch 34/1000\n",
      "200/200 [==============================] - 0s 581us/step - loss: 0.0073\n",
      "Epoch 35/1000\n",
      "200/200 [==============================] - 0s 579us/step - loss: 0.0067\n",
      "Epoch 36/1000\n",
      "200/200 [==============================] - 0s 610us/step - loss: 0.0062\n",
      "Epoch 37/1000\n",
      "200/200 [==============================] - 0s 579us/step - loss: 0.0066\n",
      "Epoch 38/1000\n",
      "200/200 [==============================] - 0s 582us/step - loss: 0.0063\n",
      "Epoch 39/1000\n",
      "200/200 [==============================] - 0s 644us/step - loss: 0.0055\n",
      "Epoch 40/1000\n",
      "200/200 [==============================] - 0s 587us/step - loss: 0.0049\n",
      "Epoch 41/1000\n",
      "200/200 [==============================] - 0s 588us/step - loss: 0.0045\n",
      "Epoch 42/1000\n",
      "200/200 [==============================] - 0s 599us/step - loss: 0.0056\n",
      "Epoch 43/1000\n",
      "200/200 [==============================] - 0s 578us/step - loss: 0.0044\n",
      "Epoch 44/1000\n",
      "200/200 [==============================] - 0s 606us/step - loss: 0.0035\n",
      "Epoch 45/1000\n",
      "200/200 [==============================] - 0s 617us/step - loss: 0.0039\n",
      "Epoch 46/1000\n",
      "200/200 [==============================] - 0s 570us/step - loss: 0.0033\n",
      "Epoch 47/1000\n",
      "200/200 [==============================] - 0s 584us/step - loss: 0.0025\n",
      "Epoch 48/1000\n",
      "200/200 [==============================] - 0s 569us/step - loss: 0.0037\n",
      "Epoch 49/1000\n",
      "200/200 [==============================] - 0s 583us/step - loss: 0.0025\n",
      "Epoch 50/1000\n",
      "200/200 [==============================] - 0s 588us/step - loss: 0.0026\n",
      "Epoch 51/1000\n",
      "200/200 [==============================] - 0s 613us/step - loss: 0.0020\n",
      "Epoch 52/1000\n",
      "200/200 [==============================] - 0s 593us/step - loss: 0.0029\n",
      "Epoch 53/1000\n",
      "200/200 [==============================] - 0s 584us/step - loss: 0.0016\n",
      "Epoch 54/1000\n",
      "200/200 [==============================] - 0s 584us/step - loss: 0.0029\n",
      "Epoch 55/1000\n",
      "200/200 [==============================] - 0s 588us/step - loss: 0.0016\n",
      "Epoch 56/1000\n",
      "200/200 [==============================] - 0s 578us/step - loss: 0.0016\n",
      "Epoch 57/1000\n",
      "200/200 [==============================] - 0s 589us/step - loss: 0.0027\n",
      "Epoch 58/1000\n",
      "200/200 [==============================] - 0s 609us/step - loss: 0.0022\n",
      "Epoch 59/1000\n",
      "200/200 [==============================] - 0s 581us/step - loss: 0.0014\n",
      "Epoch 60/1000\n",
      "200/200 [==============================] - 0s 588us/step - loss: 0.0012\n",
      "Epoch 61/1000\n",
      "200/200 [==============================] - 0s 590us/step - loss: 0.0017\n",
      "Epoch 62/1000\n",
      "200/200 [==============================] - 0s 578us/step - loss: 0.0025\n",
      "Epoch 63/1000\n",
      "200/200 [==============================] - 0s 592us/step - loss: 0.0024\n",
      "Epoch 64/1000\n",
      "200/200 [==============================] - 0s 622us/step - loss: 7.4266e-04\n",
      "Epoch 65/1000\n",
      "200/200 [==============================] - 0s 577us/step - loss: 0.0014\n",
      "Epoch 66/1000\n",
      "200/200 [==============================] - 0s 577us/step - loss: 0.0021\n",
      "Epoch 67/1000\n",
      "200/200 [==============================] - 0s 579us/step - loss: 9.6674e-04\n",
      "Epoch 68/1000\n",
      "200/200 [==============================] - 0s 580us/step - loss: 0.0017\n",
      "Epoch 69/1000\n",
      "200/200 [==============================] - 0s 587us/step - loss: 0.0011\n",
      "Epoch 70/1000\n",
      "200/200 [==============================] - 0s 622us/step - loss: 0.0020\n",
      "Epoch 71/1000\n",
      "200/200 [==============================] - 0s 579us/step - loss: 0.0017\n",
      "Epoch 72/1000\n",
      "200/200 [==============================] - 0s 581us/step - loss: 0.0011\n",
      "Epoch 73/1000\n",
      "200/200 [==============================] - 0s 578us/step - loss: 0.0011\n",
      "Epoch 74/1000\n",
      "200/200 [==============================] - 0s 603us/step - loss: 0.0024\n",
      "Epoch 75/1000\n",
      "200/200 [==============================] - 0s 590us/step - loss: 0.0011\n",
      "Epoch 76/1000\n",
      "200/200 [==============================] - 0s 590us/step - loss: 0.0013\n",
      "Epoch 77/1000\n",
      "200/200 [==============================] - 0s 581us/step - loss: 9.9333e-04\n",
      "Epoch 78/1000\n",
      "200/200 [==============================] - 0s 588us/step - loss: 0.0014\n",
      "Epoch 79/1000\n",
      "200/200 [==============================] - 0s 622us/step - loss: 8.6512e-04\n",
      "Epoch 80/1000\n",
      "200/200 [==============================] - 0s 589us/step - loss: 0.0021\n",
      "Epoch 81/1000\n",
      "200/200 [==============================] - 0s 605us/step - loss: 0.0010\n",
      "Epoch 82/1000\n",
      "200/200 [==============================] - 0s 586us/step - loss: 0.0019\n",
      "Epoch 83/1000\n",
      "200/200 [==============================] - 0s 578us/step - loss: 9.5279e-04\n",
      "Epoch 84/1000\n",
      "200/200 [==============================] - 0s 615us/step - loss: 0.0013\n",
      "Epoch 85/1000\n",
      "200/200 [==============================] - 0s 585us/step - loss: 8.6799e-04\n",
      "Epoch 86/1000\n",
      "200/200 [==============================] - 0s 585us/step - loss: 0.0014\n",
      "Epoch 87/1000\n",
      "200/200 [==============================] - 0s 588us/step - loss: 0.0010\n",
      "Epoch 88/1000\n",
      "200/200 [==============================] - 0s 618us/step - loss: 0.0015\n",
      "Epoch 89/1000\n",
      "200/200 [==============================] - 0s 609us/step - loss: 7.6797e-04\n",
      "Epoch 90/1000\n",
      "200/200 [==============================] - 0s 588us/step - loss: 0.0023\n",
      "Epoch 91/1000\n",
      "200/200 [==============================] - 0s 584us/step - loss: 0.0010\n",
      "Epoch 92/1000\n",
      "200/200 [==============================] - 0s 613us/step - loss: 0.0010\n",
      "Epoch 93/1000\n",
      "200/200 [==============================] - 0s 586us/step - loss: 7.2576e-04\n",
      "Epoch 94/1000\n",
      "200/200 [==============================] - 0s 583us/step - loss: 0.0013\n",
      "Epoch 95/1000\n",
      "200/200 [==============================] - 0s 588us/step - loss: 0.0012\n",
      "Epoch 96/1000\n",
      "200/200 [==============================] - 0s 612us/step - loss: 0.0012\n",
      "Epoch 97/1000\n",
      "200/200 [==============================] - 0s 588us/step - loss: 0.0011\n",
      "Epoch 98/1000\n",
      "200/200 [==============================] - 0s 605us/step - loss: 0.0014\n",
      "Epoch 99/1000\n",
      "200/200 [==============================] - 0s 595us/step - loss: 9.3442e-04\n",
      "Epoch 100/1000\n",
      "200/200 [==============================] - 0s 610us/step - loss: 9.7536e-04\n",
      "Epoch 101/1000\n",
      "200/200 [==============================] - 0s 594us/step - loss: 0.0014\n",
      "Epoch 102/1000\n",
      "200/200 [==============================] - 0s 923us/step - loss: 9.4161e-04\n",
      "Epoch 103/1000\n",
      "200/200 [==============================] - 0s 580us/step - loss: 0.0015\n",
      "Epoch 104/1000\n",
      "200/200 [==============================] - 0s 622us/step - loss: 9.9740e-04\n",
      "Epoch 105/1000\n",
      "200/200 [==============================] - 0s 590us/step - loss: 0.0015\n",
      "Epoch 106/1000\n",
      "200/200 [==============================] - 0s 605us/step - loss: 8.8441e-04\n",
      "Epoch 107/1000\n",
      "200/200 [==============================] - 0s 584us/step - loss: 9.5328e-04\n",
      "Epoch 108/1000\n",
      "200/200 [==============================] - 0s 657us/step - loss: 0.0016\n",
      "Epoch 109/1000\n",
      "200/200 [==============================] - 0s 606us/step - loss: 7.1702e-04\n",
      "Epoch 110/1000\n",
      "200/200 [==============================] - 0s 677us/step - loss: 0.0011\n",
      "Epoch 111/1000\n",
      "200/200 [==============================] - 0s 633us/step - loss: 0.0010\n",
      "Epoch 112/1000\n",
      "200/200 [==============================] - 0s 668us/step - loss: 9.3409e-04\n",
      "Epoch 113/1000\n",
      "200/200 [==============================] - 0s 584us/step - loss: 0.0011\n",
      "Epoch 114/1000\n",
      "200/200 [==============================] - 0s 699us/step - loss: 0.0012\n",
      "Epoch 115/1000\n",
      "200/200 [==============================] - 0s 707us/step - loss: 0.0026\n",
      "Epoch 116/1000\n",
      "200/200 [==============================] - 0s 706us/step - loss: 5.5324e-04\n",
      "Epoch 117/1000\n",
      "200/200 [==============================] - 0s 697us/step - loss: 7.2268e-04\n",
      "Epoch 118/1000\n",
      "200/200 [==============================] - 0s 782us/step - loss: 5.2454e-04\n",
      "Epoch 119/1000\n",
      "200/200 [==============================] - 0s 822us/step - loss: 0.0015\n",
      "Epoch 120/1000\n",
      "200/200 [==============================] - 0s 633us/step - loss: 6.0128e-04\n",
      "Epoch 121/1000\n",
      "200/200 [==============================] - 0s 633us/step - loss: 0.0014\n",
      "Epoch 122/1000\n",
      "200/200 [==============================] - 0s 610us/step - loss: 0.0013\n",
      "Epoch 123/1000\n",
      "200/200 [==============================] - 0s 693us/step - loss: 8.9091e-04\n",
      "Epoch 124/1000\n",
      "200/200 [==============================] - 0s 585us/step - loss: 8.2317e-04\n",
      "Epoch 125/1000\n",
      "200/200 [==============================] - 0s 611us/step - loss: 8.4357e-04\n",
      "Epoch 126/1000\n",
      "200/200 [==============================] - 0s 649us/step - loss: 9.7495e-04\n",
      "Epoch 127/1000\n",
      "200/200 [==============================] - 0s 659us/step - loss: 9.9697e-04\n",
      "Epoch 128/1000\n",
      "200/200 [==============================] - 0s 609us/step - loss: 0.0012\n",
      "Epoch 129/1000\n",
      "200/200 [==============================] - 0s 603us/step - loss: 5.8389e-04\n",
      "Epoch 130/1000\n",
      "200/200 [==============================] - 0s 631us/step - loss: 0.0018\n",
      "Epoch 131/1000\n",
      "200/200 [==============================] - 0s 637us/step - loss: 6.5660e-04\n",
      "Epoch 132/1000\n",
      "200/200 [==============================] - 0s 592us/step - loss: 8.6108e-04\n",
      "Epoch 133/1000\n",
      "200/200 [==============================] - 0s 749us/step - loss: 0.0015\n",
      "Epoch 134/1000\n",
      "200/200 [==============================] - 0s 702us/step - loss: 0.0017\n",
      "Epoch 135/1000\n",
      "200/200 [==============================] - 0s 617us/step - loss: 4.2346e-04\n",
      "Epoch 136/1000\n",
      "200/200 [==============================] - 0s 818us/step - loss: 4.1086e-04\n",
      "Epoch 137/1000\n",
      "200/200 [==============================] - 0s 762us/step - loss: 0.0012\n",
      "Epoch 138/1000\n",
      "200/200 [==============================] - 0s 718us/step - loss: 9.5585e-04\n",
      "Epoch 139/1000\n",
      "200/200 [==============================] - 0s 621us/step - loss: 8.0640e-04\n",
      "Epoch 140/1000\n",
      "200/200 [==============================] - 0s 715us/step - loss: 0.0020\n",
      "Epoch 141/1000\n",
      "200/200 [==============================] - 0s 602us/step - loss: 5.6747e-04\n",
      "Epoch 142/1000\n",
      "200/200 [==============================] - 0s 674us/step - loss: 8.2997e-04\n",
      "Epoch 143/1000\n",
      "200/200 [==============================] - 0s 613us/step - loss: 7.5647e-04\n",
      "Epoch 144/1000\n",
      "200/200 [==============================] - 0s 917us/step - loss: 8.0784e-04\n",
      "Epoch 145/1000\n",
      "200/200 [==============================] - 0s 849us/step - loss: 8.9902e-04\n",
      "Epoch 146/1000\n",
      "200/200 [==============================] - 0s 661us/step - loss: 7.3956e-04\n",
      "Epoch 147/1000\n",
      "200/200 [==============================] - 0s 716us/step - loss: 0.0013\n",
      "Epoch 148/1000\n",
      "200/200 [==============================] - 0s 665us/step - loss: 7.2132e-04\n",
      "Epoch 149/1000\n",
      "200/200 [==============================] - 0s 629us/step - loss: 7.5715e-04\n",
      "Epoch 150/1000\n",
      "200/200 [==============================] - 0s 705us/step - loss: 8.2282e-04\n",
      "Epoch 151/1000\n",
      "200/200 [==============================] - 0s 632us/step - loss: 8.8572e-04\n",
      "Epoch 152/1000\n",
      "200/200 [==============================] - 0s 666us/step - loss: 0.0013\n",
      "Epoch 153/1000\n",
      "200/200 [==============================] - 0s 640us/step - loss: 5.6112e-04\n",
      "Epoch 154/1000\n",
      "200/200 [==============================] - 0s 635us/step - loss: 6.7465e-04\n",
      "Epoch 155/1000\n",
      "200/200 [==============================] - 0s 836us/step - loss: 0.0013\n",
      "Epoch 156/1000\n",
      "200/200 [==============================] - 0s 647us/step - loss: 4.4669e-04\n",
      "Epoch 157/1000\n",
      "200/200 [==============================] - 0s 643us/step - loss: 6.2026e-04\n",
      "Epoch 158/1000\n",
      "200/200 [==============================] - 0s 669us/step - loss: 0.0012\n",
      "Epoch 159/1000\n",
      "200/200 [==============================] - 0s 699us/step - loss: 7.0430e-04\n",
      "Epoch 160/1000\n",
      "200/200 [==============================] - 0s 606us/step - loss: 8.8597e-04\n",
      "Epoch 161/1000\n",
      "200/200 [==============================] - 0s 676us/step - loss: 6.6861e-04\n",
      "Epoch 162/1000\n",
      "200/200 [==============================] - 0s 571us/step - loss: 8.0182e-04\n",
      "Epoch 163/1000\n",
      "200/200 [==============================] - 0s 596us/step - loss: 0.0012\n",
      "Epoch 164/1000\n",
      "200/200 [==============================] - 0s 632us/step - loss: 9.7828e-04\n",
      "Epoch 165/1000\n",
      "200/200 [==============================] - 0s 609us/step - loss: 5.6328e-04\n",
      "Epoch 166/1000\n",
      "200/200 [==============================] - 0s 648us/step - loss: 7.6496e-04\n",
      "Epoch 167/1000\n",
      "200/200 [==============================] - 0s 594us/step - loss: 7.7661e-04\n",
      "Epoch 168/1000\n",
      "200/200 [==============================] - 0s 595us/step - loss: 7.3222e-04\n",
      "Epoch 169/1000\n",
      "200/200 [==============================] - 0s 635us/step - loss: 7.6340e-04\n",
      "Epoch 170/1000\n",
      "200/200 [==============================] - 0s 665us/step - loss: 8.2381e-04\n",
      "Epoch 171/1000\n",
      "200/200 [==============================] - 0s 726us/step - loss: 9.7839e-04\n",
      "Epoch 172/1000\n",
      "200/200 [==============================] - 0s 683us/step - loss: 6.0140e-04\n",
      "Epoch 173/1000\n",
      "200/200 [==============================] - 0s 582us/step - loss: 8.4135e-04\n",
      "Epoch 174/1000\n",
      "200/200 [==============================] - 0s 621us/step - loss: 5.9725e-04\n",
      "Epoch 175/1000\n",
      "200/200 [==============================] - 0s 607us/step - loss: 0.0014\n",
      "Epoch 176/1000\n",
      "200/200 [==============================] - 0s 614us/step - loss: 4.2962e-04\n",
      "Epoch 177/1000\n",
      "200/200 [==============================] - 0s 649us/step - loss: 4.8804e-04\n",
      "Epoch 178/1000\n",
      "200/200 [==============================] - 0s 582us/step - loss: 6.4454e-04\n",
      "Epoch 179/1000\n",
      "200/200 [==============================] - 0s 642us/step - loss: 7.8267e-04\n",
      "Epoch 180/1000\n",
      "200/200 [==============================] - 0s 701us/step - loss: 9.1296e-04\n",
      "Epoch 181/1000\n",
      "200/200 [==============================] - 0s 735us/step - loss: 0.0015\n",
      "Epoch 182/1000\n",
      "200/200 [==============================] - 0s 631us/step - loss: 5.6223e-04\n",
      "Epoch 183/1000\n",
      "200/200 [==============================] - 0s 636us/step - loss: 4.5501e-04\n",
      "Epoch 184/1000\n",
      "200/200 [==============================] - 0s 656us/step - loss: 9.4945e-04\n",
      "Epoch 185/1000\n",
      "200/200 [==============================] - 0s 619us/step - loss: 6.6917e-04\n",
      "Epoch 186/1000\n",
      "200/200 [==============================] - 0s 611us/step - loss: 4.7400e-04\n",
      "Epoch 187/1000\n",
      "200/200 [==============================] - 0s 609us/step - loss: 5.6155e-04\n",
      "Epoch 188/1000\n",
      "200/200 [==============================] - 0s 634us/step - loss: 6.7841e-04\n",
      "Epoch 189/1000\n",
      "200/200 [==============================] - 0s 631us/step - loss: 9.6881e-04\n",
      "Epoch 190/1000\n",
      "200/200 [==============================] - 0s 670us/step - loss: 9.1214e-04\n",
      "Epoch 191/1000\n",
      "200/200 [==============================] - 0s 663us/step - loss: 4.3018e-04\n",
      "Epoch 192/1000\n",
      "200/200 [==============================] - 0s 644us/step - loss: 7.2722e-04\n",
      "Epoch 193/1000\n",
      "200/200 [==============================] - 0s 583us/step - loss: 5.3810e-04\n",
      "Epoch 194/1000\n",
      "200/200 [==============================] - 0s 589us/step - loss: 7.1216e-04\n",
      "Epoch 195/1000\n",
      "200/200 [==============================] - 0s 618us/step - loss: 8.4294e-04\n",
      "Epoch 196/1000\n",
      "200/200 [==============================] - 0s 599us/step - loss: 7.1692e-04\n",
      "Epoch 197/1000\n",
      "200/200 [==============================] - 0s 574us/step - loss: 0.0010\n",
      "Epoch 198/1000\n",
      "200/200 [==============================] - 0s 962us/step - loss: 5.9193e-04\n",
      "Epoch 199/1000\n",
      "200/200 [==============================] - 0s 641us/step - loss: 3.8086e-04\n",
      "Epoch 200/1000\n",
      "200/200 [==============================] - 0s 702us/step - loss: 8.2525e-04\n",
      "Epoch 201/1000\n",
      "200/200 [==============================] - 0s 620us/step - loss: 4.6951e-04\n",
      "Epoch 202/1000\n",
      "200/200 [==============================] - 0s 615us/step - loss: 7.5807e-04\n",
      "Epoch 203/1000\n",
      "200/200 [==============================] - 0s 679us/step - loss: 3.2485e-04\n",
      "Epoch 204/1000\n",
      "200/200 [==============================] - 0s 616us/step - loss: 6.1354e-04\n",
      "Epoch 205/1000\n",
      "200/200 [==============================] - 0s 677us/step - loss: 7.6393e-04\n",
      "Epoch 206/1000\n",
      "200/200 [==============================] - 0s 629us/step - loss: 0.0012\n",
      "Epoch 207/1000\n",
      "200/200 [==============================] - 0s 627us/step - loss: 7.8630e-04\n",
      "Epoch 208/1000\n",
      "200/200 [==============================] - 0s 649us/step - loss: 5.6449e-04\n",
      "Epoch 209/1000\n",
      "200/200 [==============================] - 0s 608us/step - loss: 3.2005e-04\n",
      "Epoch 210/1000\n",
      "200/200 [==============================] - 0s 588us/step - loss: 4.7608e-04\n",
      "Epoch 211/1000\n",
      "200/200 [==============================] - 0s 630us/step - loss: 9.1489e-04\n",
      "Epoch 212/1000\n",
      "200/200 [==============================] - 0s 596us/step - loss: 4.0901e-04\n",
      "Epoch 213/1000\n",
      "200/200 [==============================] - 0s 613us/step - loss: 4.8027e-04\n",
      "Epoch 214/1000\n",
      "200/200 [==============================] - 0s 593us/step - loss: 7.5106e-04\n",
      "Epoch 215/1000\n",
      "200/200 [==============================] - 0s 744us/step - loss: 5.8404e-04\n",
      "Epoch 216/1000\n",
      "200/200 [==============================] - 0s 780us/step - loss: 4.6642e-04\n",
      "Epoch 217/1000\n",
      "200/200 [==============================] - 0s 672us/step - loss: 8.5413e-04\n",
      "Epoch 218/1000\n",
      "200/200 [==============================] - 0s 655us/step - loss: 6.1534e-04\n",
      "Epoch 219/1000\n",
      "200/200 [==============================] - 0s 659us/step - loss: 5.7130e-04\n",
      "Epoch 220/1000\n",
      "200/200 [==============================] - 0s 673us/step - loss: 9.8617e-04\n",
      "Epoch 221/1000\n",
      "200/200 [==============================] - 0s 612us/step - loss: 4.7158e-04\n",
      "Epoch 222/1000\n",
      "200/200 [==============================] - 0s 636us/step - loss: 4.6200e-04\n",
      "Epoch 223/1000\n",
      "200/200 [==============================] - 0s 592us/step - loss: 6.4245e-04\n",
      "Epoch 224/1000\n",
      "200/200 [==============================] - 0s 593us/step - loss: 3.6912e-04\n",
      "Epoch 225/1000\n",
      "200/200 [==============================] - 0s 625us/step - loss: 8.5480e-04\n",
      "Epoch 226/1000\n",
      "200/200 [==============================] - 0s 591us/step - loss: 5.0772e-04\n",
      "Epoch 227/1000\n",
      "200/200 [==============================] - 0s 591us/step - loss: 5.8208e-04\n",
      "Epoch 228/1000\n",
      "200/200 [==============================] - 0s 703us/step - loss: 4.4518e-04\n",
      "Epoch 229/1000\n",
      "200/200 [==============================] - 0s 660us/step - loss: 3.4659e-04\n",
      "Epoch 230/1000\n",
      "200/200 [==============================] - 0s 683us/step - loss: 8.8199e-04\n",
      "Epoch 231/1000\n",
      "200/200 [==============================] - 0s 598us/step - loss: 3.7260e-04\n",
      "Epoch 232/1000\n",
      "200/200 [==============================] - 0s 647us/step - loss: 6.4584e-04\n",
      "Epoch 233/1000\n",
      "200/200 [==============================] - 0s 645us/step - loss: 5.6383e-04\n",
      "Epoch 234/1000\n",
      "200/200 [==============================] - 0s 602us/step - loss: 5.2982e-04\n",
      "Epoch 235/1000\n",
      "200/200 [==============================] - 0s 818us/step - loss: 6.9480e-04\n",
      "Epoch 236/1000\n",
      "200/200 [==============================] - 0s 706us/step - loss: 4.5123e-04\n",
      "Epoch 237/1000\n",
      "200/200 [==============================] - 0s 595us/step - loss: 5.8849e-04\n",
      "Epoch 238/1000\n",
      "200/200 [==============================] - 0s 582us/step - loss: 7.4912e-04\n",
      "Epoch 239/1000\n",
      "200/200 [==============================] - 0s 580us/step - loss: 4.8076e-04\n",
      "Epoch 240/1000\n",
      "200/200 [==============================] - 0s 611us/step - loss: 7.1579e-04\n",
      "Epoch 241/1000\n",
      "200/200 [==============================] - 0s 586us/step - loss: 4.3216e-04\n",
      "Epoch 242/1000\n",
      "200/200 [==============================] - 0s 603us/step - loss: 5.2168e-04\n",
      "Epoch 243/1000\n",
      "200/200 [==============================] - 0s 663us/step - loss: 3.8254e-04\n",
      "Epoch 244/1000\n",
      "200/200 [==============================] - 0s 583us/step - loss: 6.2167e-04\n",
      "Epoch 245/1000\n",
      "200/200 [==============================] - 0s 667us/step - loss: 4.2368e-04\n",
      "Epoch 246/1000\n",
      "200/200 [==============================] - 0s 623us/step - loss: 3.7479e-04\n",
      "Epoch 247/1000\n",
      " 78/200 [==========>...................] - ETA: 0s - loss: 7.2137e-04"
     ]
    }
   ],
   "source": [
    "model_lstm_PI = rnn.simple_rnn(n_hidden=32, n_layers=1, input_shape=(2, spacial_dim))\n",
    "\n",
    "pi_loss = lf.loss(momentum_conservation=True, momentum_weight=0.5)\n",
    "\n",
    "model_lstm_PI.build(optimizer='adam', loss=pi_loss.custom_loss)\n",
    "\n",
    "model_lstm_PI.fit(train_inputs, train_targets, n_epochs)\n",
    "model_lstm_PI.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('multi_1000_32.h5')\n",
    "\n",
    "pred_seq_lstm = model_lstm.test(sequenced_test_inputs, test_indx)\n",
    "pred_seq_lstm_PI = model_lstm_PI.test(sequenced_test_inputs, test_indx)\n",
    "# model.save('multi.h5')\n",
    "\n",
    "\n",
    "# ## Visualisation\n",
    "\n",
    "# separate x,y,z\n",
    "\n",
    "pred_seq_lstm = pred_seq_lstm.reshape(-1, spacial_dim)\n",
    "pred_seq_lstm_PI = pred_seq_lstm_PI.reshape(-1, spacial_dim)\n",
    "\n",
    "# Extract x, y, z coordinates from predicted sequence\n",
    "pred_x_lstm = pred_seq_lstm[:, 0]\n",
    "pred_y_lstm = pred_seq_lstm[:, 1]\n",
    "pred_z_lstm = pred_seq_lstm[:, 2]\n",
    "\n",
    "pred_x_lstm_PI = pred_seq_lstm_PI[:, 0]\n",
    "pred_y_lstm_PI= pred_seq_lstm_PI[:, 1]\n",
    "pred_z_lstm_PI = pred_seq_lstm_PI[:, 2]\n",
    "\n",
    "# Extract x, y, z coordinates from test data\n",
    "test_x = sequenced_test_targets[test_indx][:, 0]\n",
    "test_y = sequenced_test_targets[test_indx][:, 1]\n",
    "test_z = sequenced_test_targets[test_indx][:, 2]\n",
    "\n",
    "# Create a 3D plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the predicted sequence\n",
    "ax.plot(pred_x_lstm, pred_y_lstm, pred_z_lstm, label='LSTM Predicted Sequence')\n",
    "ax.plot(pred_x_lstm_PI, pred_y_lstm_PI, pred_z_lstm_PI, label='LSTM PI Predicted Sequence')\n",
    "\n",
    "\n",
    "# Plot the test data\n",
    "ax.plot(test_x, test_y, test_z, label='Test Data', linestyle='-.')\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.set_title('Predicted Sequence vs Test Data')\n",
    "\n",
    "# Add a legend\n",
    "ax.legend()\n",
    "\n",
    "# save plot\n",
    "plt.savefig('./Analysis/figs/lorenz_rnn.pdf')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# pg vis\n",
    "\n",
    "#py_visualiser(dataset=raw_data, seq_pos=pred_seq)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit ('3.10.2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "725bbe29d1c18d191ac0c85feb075f75ad20654624becd29588183ed39edd8e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
